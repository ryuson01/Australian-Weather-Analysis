This script contains comprehensive code for loading, summarizing, analyzing, and visualizing the dataset.

# Load SparkR package
library(SparkR) 

# Load file into data frame
df <- read.df("/FileStore/AustraliaWeatherData.csv", source = "csv", header="true", inferSchema = "true") 
head(df) 

# Copy file to personal database to prevent loss of data file when loaded into Hive table
%fs cp "/FileStore/tables/AustraliaWeatherData.csv" 
"/users/ryuson/AustraliaWeatherData.csv" 

########## Create Hive Table
# Set language to SQL
%sql 
DROP TABLE IF EXISTS weather_full; 

CREATE TABLE weather_full (
`Date` DATE, Location STRING, 
MinTemp DOUBLE, MaxTemp DOUBLE, 
Rainfall DOUBLE, Evaporation DOUBLE, Sunshine DOUBLE, 
WindGustDir STRING, WindGustSpeed DOUBLE, 
WindDir9am STRING, WindDir3pm STRING, 
WindSpeed9am DOUBLE, WindSpeed3pm DOUBLE,
Humidity9am DOUBLE, Humidity3pm DOUBLE, 
Pressure9am DOUBLE, Pressure3pm DOUBLE, 
Cloud9am DOUBLE, Cloud3pm DOUBLE, 
Temp9am DOUBLE, Temp3pm DOUBLE, 
RainToday STRING, RainTomorrow STRING) 

USING CSV 
LOCATION '/users/ryuson/AustraliaWeatherData.csv'; 

########## Enable dynamic partitioning
%sql 
SET hive.exec.dynamic.partition =  TRUE; 
SET hive.exec.dynamic.partition.mode = nonstrict; 
SET hive.exec.max.dynamic.partitions = 1500; 

# Create Year partitioned table
%sql
CREATE TABLE IF NOT  EXISTS year_part (
Location STRING, 
MinTemp DOUBLE, MaxTemp DOUBLE, 
Rainfall DOUBLE, Evaporation DOUBLE, Sunshine DOUBLE, 
WindGustDir STRING, WindGustSpeed DOUBLE,
WindDir9am STRING, WindDir3pm STRING, 
WindSpeed9am DOUBLE, WindSpeed3pm DOUBLE,
Humidity9am DOUBLE, Humidity3pm DOUBLE, 
Pressure9am DOUBLE, Pressure3pm DOUBLE,
Cloud9am DOUBLE, Cloud3pm DOUBLE, 
Temp9am DOUBLE, Temp3pm DOUBLE, 
RainToday STRING, RainTomorrow STRING, 
`Date` DATE, `Year` INT) 

PARTITIONED BY (year_part INT) 
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',' 
LINES TERMINATED BY '\n' 
STORED AS TEXTFILE;

# Load data into the partitioned table
# Use year() function to derive the year from the date column and partition the data by the derived column
%sql 
INSERT OVERWRITE TABLE year_part 
PARTITION (`Year`) 
SELECT *, 
Year(`Date`) AS `Year` FROM weather_full; 

########## Data Summarization with HiveQL ##########
## NOTE: Set cell language to SQL, given that the notebook's default language is R
%sql 

--- How many instances do we have in each year? 
USE ryuson;
SELECT `Year`, count (*) as Total_Instances 
FROM year_part 
GROUP BY `Year` 
ORDER BY `Year`; 

-- How many months of data are available each year? 
SELECT year, month(Date) as month 
FROM year_part 
GROUP BY year, month 
ORDER BY year, month; 

-- Which areas of Australia experience the most precipitation?
SELECT Location, round(avg(Rainfall),2) AS Avg_Rainfall_cm 
FROM weather_full 
GROUP BY Location 
ORDER BY avg(Rainfall) DESC 
LIMIT 10; 

-- What are the locations with the top 10 highest rainfall? Which years had the highest rainfall for these locations?
SELECT location, year, max(Rainfall) as max_rainfall 
FROM year_part 
GROUP BY location, year 
ORDER BY max_rainfall desc 
LIMIT 10; 

--- What do monthly rain patterns look like in the location with the highest rainfall? 
SELECT location, CAST(year(date) AS INT) || '-' || CAST(month(date) AS INT) AS YearMonth, round(avg(Rainfall),2) AS Avg_Rainfall_cm 
FROM weather_full 
Where location = "Cairns" 
GROUP BY month(date), year(date), location 
ORDER BY CAST(Year(date) AS INT), CAST(Month(date) AS INT) ASC;

--- Look at instances in 2011 where rainfall was higher than average to identify any outliers.
SELECT * 
FROM year_part 
WHERE Location = "Cairns" 
AND `Year` = 2011 
AND month(`Date`) = 2 
AND Rainfall > 35.69; 

--- Which areas have experienced the highest temperatures? 
SELECT Location, max(MaxTemp) AS MaxTemp 
FROM weather_full 
GROUP BY Location 
ORDER BY MaxTemp desc 
LIMIT 10; 

-- How have general weather patterns changed over time? 
-- Compare average numeric weather features. 
SELECT year, 
round(avg(MinTemp), 2) AS AvgMinTemp, 
round(avg(MaxTemp), 2) AS AvgMaxTemp,  
round(avg(Sunshine), 2) AS AvgEvaporation, 
round(avg(Sunshine), 2) AS AvgSunshine, 
round(avg(Rainfall), 2) AS AvgRainfall 
FROM year_part 
WHERE year != "2007" AND year != "2017" 
GROUP BY year 
ORDER BY year; 

â€“ How are general/static weather characteristics (rain, evaporation, and sunshine) correlated?
SELECT corr(Sunshine, Evaporation) AS sun_evap,
corr(Sunshine, Rainfall) AS sun_rain, 
corr(Rainfall, Evaporation) AS rain_evap 
FROM year_part; 

-- Have daily/dynamic weather characteristics become more variable over time? 
-- Compare changes in morning/afternoon weather measurements by year. 
SELECT year,
round(avg(WindSpeed9am), 2) AS AvgWindSpeed9am, round(avg(WindSpeed3pm), 2) AS AvgWindSpeed3pm,  
round(avg(Humidity9am), 2) AS AvgHumidity9am, round(avg(Humidity3pm), 2) AS AvgHumidity3pm,  
round(avg(Pressure9am), 2) AS AvgPressure9am, round(avg(Pressure3pm), 2) AS AvgPressure3pm, 
round(avg(Cloud9am), 2) AS AvgCloud9am, round(avg(Cloud3pm), 2) AS AvgCloud3pm, 
round(avg(Temp9am), 2) AS AvgTemp9am, round(avg(Temp3pm), 2) AS AvgTemp3pm 
FROM year_part 
WHERE year != "2007" AND year != "2017" 
GROUP BY year 
ORDER BY year; 

########## Data Analysis and Model Performance ##########
# NOTE: The following code is written in R, in accordance with the notebook's default language

# How accurately can we predict the high temperature of a day based on the temperatures recorded throughout the day? 
# Regression (MSE/RMSE)

df2<-dropna(df)

#Split data into training/testing
df_list <- randomSplit(df2, c(7,3), 2) 
training<-df_list[[1]]
testing<-df_list[[2]]

#Create general linear model
#Predict MaxTemp using 9AM and 3PM temperatures
temp_model <- spark.glm(training,                                   
                        MaxTemp ~ Temp9am + Temp3pm,                                      
                        family = "gaussian") 
 
Output_temp <- predict(temp_model, testing)
Output <- select(Output_temp, Output_temp$MaxTemp, Output_temp$Temp9am, Output_temp$Temp3pm, Output_temp$prediction)

#Show output
showDF(Output,10) 
 
#MSE
showDF(select(Output_temp, avg((Output_temp$MaxTemp-Output_temp$prediction)^2)))
 
 
#RMSE (1.087)
showDF(select(Output_temp, 
           sqrt(avg((Output_temp$MaxTemp-Output_temp$prediction)^2))))
 
#MAPE (3.26%)
showDF(select(Output_temp, 
    avg(abs(Output_temp$MaxTemp-  
            Output_temp$prediction)/abs(Output_temp$MaxTemp)))) 


# Visualize Actual vs. Predicted Max Temperatures
library(ggplot2)

# Convert to R data frame to utilize for scatterplot
rfr_df <- collect(Output_temp)

qplot(rfr_df$MaxTemp, rfr_df$prediction, xlab='Actual High Temp', ylab='Predicted HighTemp', 
main='Actual vs Predicted High Temperature')

########## Classification - Logistic Regression
# Which features predict raintomrrow with the highest accuracy?
# Split training/testing sets
df_list <- randomSplit(df, c(7,3), 2) 
training_df <- df_list[[1]]
testing_df <- df_list[[2]]
 
model_log <- spark.logit(training_df, 
                RainTomorrow ~ . - Date, 
                regParam = 0.2, #regularization parameter (>=0)
                elasticNetParam=0, #regularization function
                family = "auto", 
                thresholds = 0.5, 
                handleInvalid = "skip")\
summary(model_log)

# Apply to test set
OutputRain <- predict(model_log, testing_df)
showDF(OutputRain) #show output
 
Correct <- nrow(where(OutputRain, OutputRain$RainTomorrow == OutputRain$prediction)) 
Total <- nrow(OutputRain)

#Performance metrics
# Accuracy
Accuracy <- Correct/Total 
 
# Precision 
TP <- nrow(where(OutputRain, OutputRain$RainTomorrow == 'Yes' & OutputRain$prediction == 'Yes')) #TP = predicted yes when the it was actually yes
FP <- nrow(where(OutputRain, OutputRain$RainTomorrow == 'No' & OutputRain$prediction == 'Yes')) #FP = predicted yes when it was actually no
Precision = TP/(TP+FP) 
 
# Recall 
FN <- nrow(where(OutputRain, OutputRain$RainTomorrow == 'Yes' & OutputRain$prediction == 'No')) #FN = predicted no when it was actually yes
Recall = TP/(TP+FN)
 
# Specificity
TN <- nrow(where(OutputRain, OutputRain$RainTomorrow == 'No' & OutputRain$prediction == 'No')) #TN = predicted no when it was no 
specificity = TN/(TN+FP)
 
# Negative predictive value
NPV = TN/(TN+FN)

# Print metrics
cat("Accuracy: ",Accuracy, "\n")
cat("Precision: ",Precision, "\n")
cat("Recall: ",Recall, "\n")
cat("Specificity: ",specificity, "\n")
cat("Negative Predictive Value: ",NPV, "\n")

########## Logistic ROC Curve
library(pROC) 

# Convert to R data frame
OutputRain_r=collect(OutputRain) 
str(OutputRain_r)

# Create new column
OutputRain_r$predPosProb=0 
for(i in 1:nrow(OutputRain_r)){
   OutputRain_r$predPosProb[i]=OutputRain_r$probability[[i]][["values"]][[2]]
}

# Actual label and predicted prob
auc(OutputRain_r$RainTomorrow, OutputRain_r$predPosProb)
rocobj <- plot.roc(OutputRain_r$RainTomorrow,OutputRain_r$predPosProb,main="ROC - Logistic Regression")

# Display curve
rocobj

########## Classification - Clustering 
# Which factors in Australian precipitation are most similar? 
# For what reasons does it appear they are similar? 
# Are there any factors that were initially expected to be similar but are not?

df3<-dropna(df)
df3$RainTomorrow <- ifelse(df3$RainTomorrow=="No",0,1)
 
# k = 2
model_km2 <- spark.kmeans(df3,~.-RainTomorrow,k=2,maxIter=20)
output_km2 <- predict(model_km2,df3)
Correct2 <- nrow(where(output_km2, output_km2$RainTomorrow==output_km2$prediction))
Total2 <- nrow(output_km2)
Accuracy2 = Correct2/Total2
 
# k = 3
model_km3 <- spark.kmeans(df3,~.-RainTomorrow,k=3,maxIter=20)
output_km3 <- predict(model_km3,df3)
Correct3 <- nrow(where(output_km3, output_km3$RainTomorrow==output_km3$prediction))
Total3 <- nrow(output_km3)
Accuracy3 = Correct3/Total3
 
# k = 4
model_km4 <- spark.kmeans(df3,~.-RainTomorrow,k=4,maxIter=20)
output_km4 <- predict(model_km4,df3)
Correct4 <- nrow(where(output_km4, output_km4$RainTomorrow==output_km4$prediction))
Total4 <- nrow(output_km4)
Accuracy4 = Correct4/Total4
 
# k = 5
model_km5 <- spark.kmeans(df3,~.-RainTomorrow,k=5,maxIter=20)
output_km5 <- predict(model_km5,df3)
Correct5 <- nrow(where(output_km5, output_km5$RainTomorrow==output_km5$prediction))
Total5 <- nrow(output_km5)
Accuracy5 = Correct5/Total5
 
# k = 6
model_km6 <- spark.kmeans(df3,~.-RainTomorrow,k=6,maxIter=20)
output_km6 <- predict(model_km6,df3)
Correct6 <- nrow(where(output_km6, output_km6$RainTomorrow==output_km6$prediction))
Total6 <- nrow(output_km6)
Accuracy6 = Correct6/Total6
 
# k = 7
model_km7 <- spark.kmeans(df3,~.-RainTomorrow,k=7,maxIter=20)
output_km7 <- predict(model_km7,df3)
Correct7 <- nrow(where(output_km7, output_km7$RainTomorrow==output_km7$prediction))
Total7 <- nrow(output_km7)
Accuracy7 = Correct7/Total7
 
# k = 10
model_km10 <- spark.kmeans(df3,~.-RainTomorrow,k=10,maxIter=20)
output_km10 <- predict(model_km10,df3)
Correct10 <- nrow(where(output_km10, output_km10$RainTomorrow==output_km10$prediction))
Total10 <- nrow(output_km10)
Accuracy10 = Correct10/Total10

# Print accuracy of each cluster
cat("Accuracy when k=2: ",Accuracy2, "\n")
cat("Accuracy when k=3: ",Accuracy3, "\n")
cat("Accuracy when k=4: ",Accuracy4, "\n")
cat("Accuracy when k=5: ",Accuracy5, "\n")
cat("Accuracy when k=6: ",Accuracy6, "\n")
cat("Accuracy when k=7: ",Accuracy7, "\n")
cat("Accuracy when k=10: ",Accuracy10)

# Remove Date & Summarize
model_km6 <- spark.kmeans(df3,~.-RainTomorrow-Date,k=6,maxIter=20)
summary(model_km6)

# Nrow in dataset; Nrow per cluster
print(nrow(df3))
print(nrow(where(output_km6,output_km6$prediction==0)))
print(nrow(where(output_km6,output_km6$prediction==1)))
print(nrow(where(output_km6,output_km6$prediction==2)))
print(nrow(where(output_km6,output_km6$prediction==3)))
print(nrow(where(output_km6,output_km6$prediction==4)))
print(nrow(where(output_km6,output_km6$prediction==5)))




